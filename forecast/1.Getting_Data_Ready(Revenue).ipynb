{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Setup\n","Import the standard Python Libraries that are used in this lab.\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":"import boto3\nfrom time import sleep\nimport subprocess\nimport pandas as pd\nimport json\nimport time"},{"cell_type":"markdown","metadata":{},"source":["Import sagemaker and get execution role for getting role ARN"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["arn:aws:iam::457927431838:role/service-role/AmazonSageMaker-ExecutionRole-20190920T105733\n"]}],"source":"import sagemaker\nregion = boto3.Session().region_name    \nsmclient = boto3.Session().client('sagemaker')\nfrom sagemaker import get_execution_role\n\nrole_arn = get_execution_role()\nprint(role_arn)\n\n#Make sure this role has the forecast permissions set to be able to use S3"},{"cell_type":"markdown","metadata":{},"source":["The last part of the setup process is to validate that your account can communicate with Amazon Forecast, the cell below does just that."]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":"session = boto3.Session(region_name='us-east-1') \nforecast = session.client(service_name='forecast') \nforecastquery = session.client(service_name='forecastquery')"},{"cell_type":"markdown","metadata":{},"source":["## Data Prepraration"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>metric_name</th>\n","      <th>timestamp</th>\n","      <th>metric_value</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>metric_name</td>\n","      <td>timestamp</td>\n","      <td>metric_value</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Revenue</td>\n","      <td>2018-12-31</td>\n","      <td>28076000000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Revenue</td>\n","      <td>2017-12-31</td>\n","      <td>27237000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   metric_name   timestamp  metric_value\n","0  metric_name   timestamp  metric_value\n","1      Revenue  2018-12-31   28076000000\n","2      Revenue  2017-12-31   27237000000"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":"df = pd.read_csv(\"../data/COF_yearly_Revenue_Data.csv\", dtype = object, names=['metric_name','timestamp','metric_value'])\ndf.head(3)"},{"cell_type":"markdown","metadata":{},"source":["Create the training set and validation set. Use the last years revenue as the validation set"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":"# Select 1996 to 2017 in one data frame\ndf_1996_2017 = df[(df['timestamp'] >= '1995-12-31') & (df['timestamp'] <= '2017-12-31')]\n\n# Select the year 2018 seprately for validation\ndf = pd.read_csv(\"../data/COF_yearly_Revenue_Data.csv\", dtype = object, names=['metric_name','timestamp','metric_value'])\ndf_2018 = df[(df['timestamp'] >= '2018-12-31')]"},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>metric_name</th>\n","      <th>timestamp</th>\n","      <th>metric_value</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>Revenue</td>\n","      <td>2017-12-31</td>\n","      <td>27237000000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Revenue</td>\n","      <td>2016-12-31</td>\n","      <td>25816000000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Revenue</td>\n","      <td>2015-12-31</td>\n","      <td>23413000000</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Revenue</td>\n","      <td>2014-12-31</td>\n","      <td>22290000000</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Revenue</td>\n","      <td>2013-12-31</td>\n","      <td>22384000000</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Revenue</td>\n","      <td>2012-12-31</td>\n","      <td>21396000000</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Revenue</td>\n","      <td>2011-12-31</td>\n","      <td>16279000000</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Revenue</td>\n","      <td>2010-12-31</td>\n","      <td>16171000000</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Revenue</td>\n","      <td>2009-12-31</td>\n","      <td>12983267000</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>Revenue</td>\n","      <td>2008-12-31</td>\n","      <td>13892686000</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>Revenue</td>\n","      <td>2007-12-31</td>\n","      <td>14584068000</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>Revenue</td>\n","      <td>2006-12-31</td>\n","      <td>12096362000</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>Revenue</td>\n","      <td>2005-12-31</td>\n","      <td>10038347000</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>Revenue</td>\n","      <td>2004-12-31</td>\n","      <td>8903135000</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>Revenue</td>\n","      <td>2003-12-31</td>\n","      <td>8201013000</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>Revenue</td>\n","      <td>2002-12-31</td>\n","      <td>8185948000</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>Revenue</td>\n","      <td>2001-12-31</td>\n","      <td>6083283000</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>Revenue</td>\n","      <td>2000-12-31</td>\n","      <td>4623301000</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>Revenue</td>\n","      <td>1999-12-31</td>\n","      <td>3424961000</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>Revenue</td>\n","      <td>1998-12-31</td>\n","      <td>2183065000</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>Revenue</td>\n","      <td>1997-12-31</td>\n","      <td>1452268000</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>Revenue</td>\n","      <td>1996-12-31</td>\n","      <td>1203046000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   metric_name   timestamp metric_value\n","2      Revenue  2017-12-31  27237000000\n","3      Revenue  2016-12-31  25816000000\n","4      Revenue  2015-12-31  23413000000\n","5      Revenue  2014-12-31  22290000000\n","6      Revenue  2013-12-31  22384000000\n","7      Revenue  2012-12-31  21396000000\n","8      Revenue  2011-12-31  16279000000\n","9      Revenue  2010-12-31  16171000000\n","10     Revenue  2009-12-31  12983267000\n","11     Revenue  2008-12-31  13892686000\n","12     Revenue  2007-12-31  14584068000\n","13     Revenue  2006-12-31  12096362000\n","14     Revenue  2005-12-31  10038347000\n","15     Revenue  2004-12-31   8903135000\n","16     Revenue  2003-12-31   8201013000\n","17     Revenue  2002-12-31   8185948000\n","18     Revenue  2001-12-31   6083283000\n","19     Revenue  2000-12-31   4623301000\n","20     Revenue  1999-12-31   3424961000\n","21     Revenue  1998-12-31   2183065000\n","22     Revenue  1997-12-31   1452268000\n","23     Revenue  1996-12-31   1203046000"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":"df_1996_2017\n"},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>metric_name</th>\n","      <th>timestamp</th>\n","      <th>metric_value</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>metric_name</td>\n","      <td>timestamp</td>\n","      <td>metric_value</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Revenue</td>\n","      <td>2018-12-31</td>\n","      <td>28076000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   metric_name   timestamp  metric_value\n","0  metric_name   timestamp  metric_value\n","1      Revenue  2018-12-31   28076000000"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":"df_2018"},{"cell_type":"markdown","metadata":{},"source":["Now export them to CSV files and place them into your data folder."]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":"df_1996_2017.to_csv(\"../data/cof-revenue-train.csv\", header=False, index=False)\ndf_2018.to_csv(\"../data/cof-revenue-validation.csv\", header=False, index=False)"},{"cell_type":"markdown","metadata":{},"source":["Define the S3 bucket name where we will upload data where Amazon Forecast will pick up the data later"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":"bucket_name = \"sagemaker-capone-forecast-useast1-02\"  # Rember to change this to the correct bucket name used for Capital One\nfolder_name = \"cone\"  # change this to the folder name of the user."},{"cell_type":"markdown","metadata":{},"source":["Upload the data to S3"]},{"cell_type":"markdown","execution_count":11,"metadata":{},"outputs":[],"source":"s3 = session.client('s3')\nkey=folder_name+\"/cof-revenue-train.csv\"\ns3.upload_file(Filename=\"../data/cof-revenue-train.csv\", Bucket=bucket_name, Key=key)"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"iam = boto3.client(\"iam\")\n\nrole_name = \"C1ForecastRoleDemo\"\nassume_role_policy_document = {\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n          \"Effect\": \"Allow\",\n          \"Principal\": {\n            \"Service\": \"forecast.amazonaws.com\"\n          },\n          \"Action\": \"sts:AssumeRole\"\n        }\n    ]\n}\n\ncreate_role_response = iam.create_role(\n    RoleName = role_name,\n    AssumeRolePolicyDocument = json.dumps(assume_role_policy_document)\n)\n\n# AmazonPersonalizeFullAccess provides access to any S3 bucket with a name that includes \"personalize\" or \"Personalize\" \n# if you would like to use a bucket with a different name, please consider creating and attaching a new policy\n# that provides read access to your bucket or attaching the AmazonS3ReadOnlyAccess policy to the role\npolicy_arn = \"arn:aws:iam::aws:policy/AmazonForecastFullAccess\"\niam.attach_role_policy(\n    RoleName = role_name,\n    PolicyArn = policy_arn\n)\n\n# Now add S3 support\niam.attach_role_policy(\n    PolicyArn='arn:aws:iam::aws:policy/AmazonS3FullAccess',\n    RoleName=role_name\n)\ntime.sleep(60) # wait for a minute to allow IAM role policy attachment to propagate\n\nrole_arn = create_role_response[\"Role\"][\"Arn\"]\nprint(role_arn)"},{"cell_type":"markdown","metadata":{},"source":["## Creating the Dataset Group and Dataset <a class=\"anchor\" id=\"dataset\"></a>\n","\n","In Amazon Forecast , a dataset is a collection of file(s) which contain data that is relevant for a forecasting task. A dataset must conform to a schema provided by Amazon Forecast. \n","\n","More details about `Domain` and dataset type can be found on the [documentation](https://docs.aws.amazon.com/forecast/latest/dg/howitworks-domains-ds-types.html) . For this example, we are using [METRICS](https://docs.aws.amazon.com/forecast/latest/dg/metrics-domain.html) domain with 3 required attributes `metrics_name`, `timestamp` and `metrics_value`.\n","\n","\n","It is importan to also convey how Amazon Forecast can understand your time-series information. That the cell immediately below does that, the next one configures your variable names for the Project, DatasetGroup, and Dataset."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":"DATASET_FREQUENCY = \"Y\" \nTIMESTAMP_FORMAT = \"yyyy-mm-dd\""},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":"project = 'cof_revenue_forecastdemo'\ndatasetName= project+'_ds'\ndatasetGroupName= project +'_dsg'\ns3DataPath = \"s3://\"+bucket_name+\"/\"+key"},{"cell_type":"markdown","metadata":{},"source":["### Create the Dataset Group"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":"create_dataset_group_response = forecast.create_dataset_group(DatasetGroupName=datasetGroupName,\n                                                              Domain=\"METRICS\",\n                                                             )\ndatasetGroupArn = create_dataset_group_response['DatasetGroupArn']"},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["{'DatasetGroupName': 'cof_revenue_forecastdemo_dsg',\n"," 'DatasetGroupArn': 'arn:aws:forecast:us-east-1:457927431838:dataset-group/cof_revenue_forecastdemo_dsg',\n"," 'DatasetArns': [],\n"," 'Domain': 'METRICS',\n"," 'Status': 'ACTIVE',\n"," 'CreationTime': datetime.datetime(2019, 10, 9, 6, 1, 58, 826000, tzinfo=tzlocal()),\n"," 'LastModificationTime': datetime.datetime(2019, 10, 9, 6, 1, 58, 826000, tzinfo=tzlocal()),\n"," 'ResponseMetadata': {'RequestId': '9fca26de-9da0-4954-b5c9-6fabecfeffd5',\n","  'HTTPStatusCode': 200,\n","  'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1',\n","   'date': 'Wed, 09 Oct 2019 06:02:00 GMT',\n","   'x-amzn-requestid': '9fca26de-9da0-4954-b5c9-6fabecfeffd5',\n","   'content-length': '280',\n","   'connection': 'keep-alive'},\n","  'RetryAttempts': 0}}"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":"forecast.describe_dataset_group(DatasetGroupArn=datasetGroupArn)"},{"cell_type":"markdown","metadata":{},"source":["### Create the Schema"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":"# Specify the schema of your dataset here. Make sure the order of columns matches the raw data files.\nschema ={\n   \"Attributes\":[\n      {\n         \"AttributeName\":\"metric_name\",\n         \"AttributeType\":\"string\"\n      },\n      {\n         \"AttributeName\":\"timestamp\",\n         \"AttributeType\":\"timestamp\"\n      },\n      {\n         \"AttributeName\":\"metric_value\",\n         \"AttributeType\":\"float\"\n      }\n   ]\n}"},{"cell_type":"markdown","metadata":{},"source":["### Create the Dataset"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":"response=forecast.create_dataset(\n                    Domain=\"METRICS\",\n                    DatasetType='TARGET_TIME_SERIES',\n                    DatasetName=datasetName,\n                    DataFrequency=DATASET_FREQUENCY, \n                    Schema = schema\n)"},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/plain":["{'DatasetArn': 'arn:aws:forecast:us-east-1:457927431838:dataset/cof_revenue_forecastdemo_ds',\n"," 'DatasetName': 'cof_revenue_forecastdemo_ds',\n"," 'Domain': 'METRICS',\n"," 'DatasetType': 'TARGET_TIME_SERIES',\n"," 'DataFrequency': 'Y',\n"," 'Schema': {'Attributes': [{'AttributeName': 'metric_name',\n","    'AttributeType': 'string'},\n","   {'AttributeName': 'timestamp', 'AttributeType': 'timestamp'},\n","   {'AttributeName': 'metric_value', 'AttributeType': 'float'}]},\n"," 'EncryptionConfig': {},\n"," 'Status': 'ACTIVE',\n"," 'CreationTime': datetime.datetime(2019, 10, 9, 6, 2, 18, 945000, tzinfo=tzlocal()),\n"," 'LastModificationTime': datetime.datetime(2019, 10, 9, 6, 2, 18, 945000, tzinfo=tzlocal()),\n"," 'ResponseMetadata': {'RequestId': 'dff13de6-b420-48ad-afd9-8ff6cc14a2c7',\n","  'HTTPStatusCode': 200,\n","  'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1',\n","   'date': 'Wed, 09 Oct 2019 06:02:20 GMT',\n","   'x-amzn-requestid': 'dff13de6-b420-48ad-afd9-8ff6cc14a2c7',\n","   'content-length': '520',\n","   'connection': 'keep-alive'},\n","  'RetryAttempts': 0}}"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":"datasetArn = response['DatasetArn']\nforecast.describe_dataset(DatasetArn=datasetArn)"},{"cell_type":"markdown","metadata":{},"source":["### Add Dataset to Dataset Group"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/plain":["{'ResponseMetadata': {'RequestId': 'd3690d18-636d-4c63-a472-dbf83410c9f2',\n","  'HTTPStatusCode': 200,\n","  'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1',\n","   'date': 'Wed, 09 Oct 2019 06:02:24 GMT',\n","   'x-amzn-requestid': 'd3690d18-636d-4c63-a472-dbf83410c9f2',\n","   'content-length': '2',\n","   'connection': 'keep-alive'},\n","  'RetryAttempts': 0}}"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":"forecast.update_dataset_group(DatasetGroupArn=datasetGroupArn, DatasetArns=[datasetArn])"},{"cell_type":"markdown","metadata":{},"source":["### Create Data Import Job\n","\n","\n","Now that Forecast knows how to understand the CSV we are providing, the next step is to import the data from S3 into Amazon Forecaast."]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":"datasetImportJobName = 'EP_DSIMPORT_JOB_TARGET'\nds_import_job_response=forecast.create_dataset_import_job(DatasetImportJobName=datasetImportJobName,\n                                                          DatasetArn=datasetArn,\n                                                          DataSource= {\n                                                              \"S3Config\" : {\n                                                                 \"Path\":s3DataPath,\n                                                                 \"RoleArn\": role_arn\n                                                              } \n                                                          },\n                                                          TimestampFormat=TIMESTAMP_FORMAT\n                                                         )"},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["arn:aws:forecast:us-east-1:457927431838:dataset-import-job/cof_revenue_forecastdemo_ds/EP_DSIMPORT_JOB_TARGET\n"]}],"source":"ds_import_job_arn=ds_import_job_response['DatasetImportJobArn']\nprint(ds_import_job_arn)"},{"cell_type":"markdown","metadata":{},"source":["Check the status of dataset, when the status change from **CREATE_IN_PROGRESS** to **ACTIVE**, we can continue to next steps. Depending on the data size. It can take 10 mins to be **ACTIVE**. This process will take 5 to 10 minutes."]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["CREATE_IN_PROGRESS\n","CREATE_IN_PROGRESS\n","CREATE_IN_PROGRESS\n","CREATE_IN_PROGRESS\n","CREATE_IN_PROGRESS\n","CREATE_IN_PROGRESS\n","CREATE_IN_PROGRESS\n","CREATE_IN_PROGRESS\n","ACTIVE\n"]}],"source":"while True:\n    dataImportStatus = forecast.describe_dataset_import_job(DatasetImportJobArn=ds_import_job_arn)['Status']\n    print(dataImportStatus)\n    if dataImportStatus != 'ACTIVE' and dataImportStatus != 'CREATE_FAILED':\n        sleep(30)\n    else:\n        break"},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"data":{"text/plain":["{'DatasetImportJobName': 'EP_DSIMPORT_JOB_TARGET',\n"," 'DatasetImportJobArn': 'arn:aws:forecast:us-east-1:457927431838:dataset-import-job/cof_revenue_forecastdemo_ds/EP_DSIMPORT_JOB_TARGET',\n"," 'DatasetArn': 'arn:aws:forecast:us-east-1:457927431838:dataset/cof_revenue_forecastdemo_ds',\n"," 'TimestampFormat': 'yyyy-mm-dd',\n"," 'DataSource': {'S3Config': {'Path': 's3://sagemaker-capone-forecast-useast1-02/cone/cof-revenue-train.csv',\n","   'RoleArn': 'arn:aws:iam::457927431838:role/service-role/AmazonSageMaker-ExecutionRole-20190920T105733'}},\n"," 'FieldStatistics': {'date': {'Count': 22,\n","   'CountDistinct': 22,\n","   'CountNull': 0,\n","   'Min': '1996-12-31T00:00:00Z',\n","   'Max': '2017-12-31T00:00:00Z'},\n","  'item': {'Count': 22, 'CountDistinct': 1, 'CountNull': 0},\n","  'target': {'Count': 22,\n","   'CountDistinct': 22,\n","   'CountNull': 0,\n","   'CountNan': 0,\n","   'Min': '1.203046E9',\n","   'Max': '2.7237E10',\n","   'Avg': 12856397727.272728,\n","   'Stddev': 8210568656.541229}},\n"," 'DataSize': 6.26780092716217e-07,\n"," 'Status': 'ACTIVE',\n"," 'CreationTime': datetime.datetime(2019, 10, 9, 6, 2, 30, 863000, tzinfo=tzlocal()),\n"," 'LastModificationTime': datetime.datetime(2019, 10, 9, 6, 6, 13, 129000, tzinfo=tzlocal()),\n"," 'ResponseMetadata': {'RequestId': '0645ea55-988b-4edc-b0c6-6358b72673cb',\n","  'HTTPStatusCode': 200,\n","  'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1',\n","   'date': 'Wed, 09 Oct 2019 06:13:20 GMT',\n","   'x-amzn-requestid': '0645ea55-988b-4edc-b0c6-6358b72673cb',\n","   'content-length': '979',\n","   'connection': 'keep-alive'},\n","  'RetryAttempts': 0}}"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":"forecast.describe_dataset_import_job(DatasetImportJobArn=ds_import_job_arn)"},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["DatasetArn: \n","arn:aws:forecast:us-east-1:457927431838:dataset-group/cof_revenue_forecastdemo_dsg\n"]}],"source":"print(\"DatasetArn: \")\nprint(datasetGroupArn)"}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}