{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Text Classification Using Keras & TensorFlow on Amazon SageMaker"]},{"cell_type":"markdown","metadata":{},"source":["## Download Data\n"," Download and unzip the dataset"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Archive:  NewsAggregatorDataset.zip\n","  inflating: data/2pageSessions.csv  \n","   creating: data/__MACOSX/\n","  inflating: data/__MACOSX/._2pageSessions.csv  \n","  inflating: data/newsCorpora.csv    \n","  inflating: data/__MACOSX/._newsCorpora.csv  \n","  inflating: data/readme.txt         \n","  inflating: data/__MACOSX/._readme.txt  \n"]}],"source":"! wget -q https://archive.ics.uci.edu/ml/machine-learning-databases/00359/NewsAggregatorDataset.zip && unzip -o NewsAggregatorDataset.zip -d data"},{"cell_type":"markdown","metadata":{},"source":["Now lets also download and unzip the pre-trained glove embedding files"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Archive:  glove.6B.zip\n","  inflating: data/glove.6B.50d.txt   \n","  inflating: data/glove.6B.100d.txt  \n","  inflating: data/glove.6B.200d.txt  \n","  inflating: data/glove.6B.300d.txt  \n"]}],"source":"! wget -q --no-check-certificate https://nlp.stanford.edu/data/glove.6B.zip && unzip -o glove.6B.zip -d data"},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[],"source":"!rm data/2pageSessions.csv data/glove.6B.200d.txt data/glove.6B.50d.txt data/glove.6B.300d.txt glove.6B.zip data/readme.txt NewsAggregatorDataset.zip && rm -rf data/__MACOSX/"},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["glove.6B.100d.txt  newsCorpora.csv\r\n"]}],"source":"!ls data"},{"cell_type":"markdown","metadata":{},"source":["## Data Exploration"]},{"cell_type":"code","execution_count":68,"metadata":{},"outputs":[],"source":"import pandas as pd\nimport tensorflow as tf\nimport re\nimport numpy as np\nimport os\n\nfrom tensorflow.python.keras.preprocessing.text import Tokenizer\nfrom tensorflow.python.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.python.keras.utils import to_categorical"},{"cell_type":"code","execution_count":69,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>TITLE</th>\n","      <th>URL</th>\n","      <th>PUBLISHER</th>\n","      <th>CATEGORY</th>\n","      <th>STORY</th>\n","      <th>HOSTNAME</th>\n","      <th>TIMESTAMP</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>Fed official says weak data caused by weather,...</td>\n","      <td>http://www.latimes.com/business/money/la-fi-mo...</td>\n","      <td>Los Angeles Times</td>\n","      <td>b</td>\n","      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n","      <td>www.latimes.com</td>\n","      <td>1394470370698</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Fed's Charles Plosser sees high bar for change...</td>\n","      <td>http://www.livemint.com/Politics/H2EvwJSK2VE6O...</td>\n","      <td>Livemint</td>\n","      <td>b</td>\n","      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n","      <td>www.livemint.com</td>\n","      <td>1394470371207</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>US open: Stocks fall after Fed official hints ...</td>\n","      <td>http://www.ifamagazine.com/news/us-open-stocks...</td>\n","      <td>IFA Magazine</td>\n","      <td>b</td>\n","      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n","      <td>www.ifamagazine.com</td>\n","      <td>1394470371550</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Fed risks falling 'behind the curve', Charles ...</td>\n","      <td>http://www.ifamagazine.com/news/fed-risks-fall...</td>\n","      <td>IFA Magazine</td>\n","      <td>b</td>\n","      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n","      <td>www.ifamagazine.com</td>\n","      <td>1394470371793</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Fed's Plosser: Nasty Weather Has Curbed Job Gr...</td>\n","      <td>http://www.moneynews.com/Economy/federal-reser...</td>\n","      <td>Moneynews</td>\n","      <td>b</td>\n","      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n","      <td>www.moneynews.com</td>\n","      <td>1394470372027</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               TITLE  \\\n","1  Fed official says weak data caused by weather,...   \n","2  Fed's Charles Plosser sees high bar for change...   \n","3  US open: Stocks fall after Fed official hints ...   \n","4  Fed risks falling 'behind the curve', Charles ...   \n","5  Fed's Plosser: Nasty Weather Has Curbed Job Gr...   \n","\n","                                                 URL          PUBLISHER  \\\n","1  http://www.latimes.com/business/money/la-fi-mo...  Los Angeles Times   \n","2  http://www.livemint.com/Politics/H2EvwJSK2VE6O...           Livemint   \n","3  http://www.ifamagazine.com/news/us-open-stocks...       IFA Magazine   \n","4  http://www.ifamagazine.com/news/fed-risks-fall...       IFA Magazine   \n","5  http://www.moneynews.com/Economy/federal-reser...          Moneynews   \n","\n","  CATEGORY                          STORY             HOSTNAME      TIMESTAMP  \n","1        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM      www.latimes.com  1394470370698  \n","2        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM     www.livemint.com  1394470371207  \n","3        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM  www.ifamagazine.com  1394470371550  \n","4        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM  www.ifamagazine.com  1394470371793  \n","5        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM    www.moneynews.com  1394470372027  "]},"execution_count":69,"metadata":{},"output_type":"execute_result"}],"source":"column_names = [\"TITLE\", \"URL\", \"PUBLISHER\", \"CATEGORY\", \"STORY\", \"HOSTNAME\", \"TIMESTAMP\"]\nnews_dataset = pd.read_csv('data/newsCorpora.csv', names=column_names, header=None, delimiter='\\t')\nnews_dataset.head()"},{"cell_type":"markdown","metadata":{},"source":["Here we first import the necessary libraries and tools such as TensorFlow, pandas and numpy. An open-source high performance data analysis library, pandas is an essential tool used in almost every Python-based data science experiment. NumPy is another Python library that provides data structures to hold multi-dimensional array data and provides many utility functions to transform that data. TensorFlow is a widely used deep learning framework that also includes the higher-level deep learning Python library called Keras. We will be using Keras to build and iterate our text classification model.\n","\n","Next we define the list of columns contained in this dataset (the format is usually described as part of the dataset as it is here). Finally, we use the ‘read_csv()’ method of the pandas library to read the dataset into memory and look at the first few lines using the ‘head()’ method.\n","\n","Remember, our goal is to accurately predict the category of any news article. So, ‘Category’ is our label or target column. For this example, we will only use the information contained in the ‘Title’ to predict the category."]},{"cell_type":"markdown","metadata":{},"source":["When should I build my own algorithm container?\n","You may not need to create a container to bring your own code to Amazon SageMaker. When you are using a framework such as Apache MXNet or TensorFlow that has direct support in SageMaker, you can simply supply the Python code that implements your algorithm using the SDK entry points for that framework. This set of supported frameworks is regularly added to, so you should check the current list to determine whether your algorithm is written in one of these common machine learning environments.\n","\n","Even if there is direct SDK support for your environment or framework, you may find it more effective to build your own container. If the code that implements your algorithm is quite complex or you need special additions to the framework, building your own container may be the right choice.\n","\n","Some of the reasons to build an already supported framework container are:\n","\n","A specific version isn't supported.\n","Configure and install your dependencies and environment.\n","Use a different training/hosting solution than provided.\n","This walkthrough shows that it is quite straightforward to build your own container. So you can still use SageMaker even if your use case is not covered by the deep learning containers that we've built for you."]},{"cell_type":"markdown","metadata":{},"source":["The Dockerfile\n","The Dockerfile describes the image that we want to build. You can think of it as describing the complete operating system installation of the system that you want to run. A Docker container running is quite a bit lighter than a full operating system, however, because it takes advantage of Linux on the host machine for the basic operations.\n","\n","For the Python science stack, we start from an official TensorFlow docker image and run the normal tools to install TensorFlow Serving. Then we add the code that implements our specific algorithm to the container and set up the right environment for it to run under.\n","\n","Let's look at the Dockerfile for this example."]},{"cell_type":"code","execution_count":70,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["# Copyright 2017-2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.\r\n","#\r\n","# Licensed under the Apache License, Version 2.0 (the \"License\"). You\r\n","# may not use this file except in compliance with the License. A copy of\r\n","# the License is located at\r\n","#\r\n","#     http://aws.amazon.com/apache2.0/\r\n","#\r\n","# or in the \"license\" file accompanying this file. This file is\r\n","# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\r\n","# ANY KIND, either express or implied. See the License for the specific\r\n","# language governing permissions and limitations under the License.\r\n","\r\n","# For more information on creating a Dockerfile\r\n","# https://docs.docker.com/compose/gettingstarted/#step-2-create-a-dockerfile\r\n","FROM tensorflow/tensorflow:1.8.0-py3\r\n","\r\n","RUN apt-get update && apt-get install -y --no-install-recommends nginx curl\r\n","\r\n","# Download TensorFlow Serving\r\n","# https://www.tensorflow.org/serving/setup#installing_the_modelserver\r\n","RUN echo \"deb [arch=amd64] http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | tee /etc/apt/sources.list.d/tensorflow-serving.list\r\n","RUN curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -\r\n","RUN apt-get update && apt-get install tensorflow-model-server\r\n","\r\n","ENV PATH=\"/opt/ml/code:${PATH}\"\r\n","\r\n","# /opt/ml and all subdirectories are utilized by SageMaker, we use the /code subdirectory to store our user code.\r\n","COPY /sagemaker_keras_text_classification /opt/ml/code\r\n","WORKDIR /opt/ml/code"]}],"source":"!cat container/Dockerfile"},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Login Succeeded\n","Sending build context to Docker daemon  25.09kB\r","\r\n","Step 1/8 : FROM tensorflow/tensorflow:1.8.0-py3\n"," ---> a83a3dd79ff9\n","Step 2/8 : RUN apt-get update && apt-get install -y --no-install-recommends nginx curl\n"," ---> Using cache\n"," ---> b2c6ee34bd63\n","Step 3/8 : RUN echo \"deb [arch=amd64] http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | tee /etc/apt/sources.list.d/tensorflow-serving.list\n"," ---> Using cache\n"," ---> a6abb67693c2\n","Step 4/8 : RUN curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -\n"," ---> Using cache\n"," ---> 191bced6e844\n","Step 5/8 : RUN apt-get update && apt-get install tensorflow-model-server\n"," ---> Using cache\n"," ---> 6a5c372c80ac\n","Step 6/8 : ENV PATH=\"/opt/ml/code:${PATH}\"\n"," ---> Using cache\n"," ---> fafb737091f1\n","Step 7/8 : COPY /sagemaker_keras_text_classification /opt/ml/code\n"," ---> Using cache\n"," ---> 322614cc2708\n","Step 8/8 : WORKDIR /opt/ml/code\n"," ---> Using cache\n"," ---> d65bd0ecc164\n","Successfully built d65bd0ecc164\n","Successfully tagged sagemaker-keras-text-classification:latest\n","The push refers to repository [325928439752.dkr.ecr.us-east-1.amazonaws.com/sagemaker-keras-text-classification]\n","ad70d2db6a48: Preparing\n","23799f216cf7: Preparing\n","2aed47ce3a8e: Preparing\n","b8ae7b672121: Preparing\n","9f68233145ee: Preparing\n","e0c4197104f9: Preparing\n","1fb2bc13bdda: Preparing\n","9136ffbbf4aa: Preparing\n","b3a9262c451e: Preparing\n","ce70cf3f2428: Preparing\n","2faed3426aa2: Preparing\n","fee4cef4c353: Preparing\n","dc657e1d2f27: Preparing\n","588d3e4e8828: Preparing\n","bf3d982208f5: Preparing\n","cd7b4cc1c2dd: Preparing\n","3a0404adc8bd: Preparing\n","82718dbf791d: Preparing\n","c8aa3ff3c3d3: Preparing\n","2faed3426aa2: Waiting\n","fee4cef4c353: Waiting\n","dc657e1d2f27: Waiting\n","588d3e4e8828: Waiting\n","bf3d982208f5: Waiting\n","cd7b4cc1c2dd: Waiting\n","3a0404adc8bd: Waiting\n","82718dbf791d: Waiting\n","c8aa3ff3c3d3: Waiting\n","1fb2bc13bdda: Waiting\n","9136ffbbf4aa: Waiting\n","b3a9262c451e: Waiting\n","ce70cf3f2428: Waiting\n","e0c4197104f9: Waiting\n","ad70d2db6a48: Layer already exists\n","23799f216cf7: Layer already exists\n","9f68233145ee: Layer already exists\n","2aed47ce3a8e: Layer already exists\n","b8ae7b672121: Layer already exists\n","e0c4197104f9: Layer already exists\n","1fb2bc13bdda: Layer already exists\n","9136ffbbf4aa: Layer already exists\n","b3a9262c451e: Layer already exists\n","ce70cf3f2428: Layer already exists\n","fee4cef4c353: Layer already exists\n","2faed3426aa2: Layer already exists\n","bf3d982208f5: Layer already exists\n","dc657e1d2f27: Layer already exists\n","588d3e4e8828: Layer already exists\n","cd7b4cc1c2dd: Layer already exists\n","82718dbf791d: Layer already exists\n","3a0404adc8bd: Layer already exists\n","c8aa3ff3c3d3: Layer already exists\n","latest: digest: sha256:a7a7e1aa7f110ffe8fcc653ddb50f908808ffd5e89cb2b9e8f838d04550f7e5b size: 4297\n"]},{"name":"stderr","output_type":"stream","text":["WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n","WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n","Configure a credential helper to remove this warning. See\n","https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n","\n"]}],"source":"%%sh\n\n# The name of our algorithm\nalgorithm_name=sagemaker-keras-text-classification\n\ncd container\n\nchmod +x sagemaker_keras_text_classification/train\nchmod +x sagemaker_keras_text_classification/serve\n\naccount=$(aws sts get-caller-identity --query Account --output text)\n\n# Get the region defined in the current configuration (default to us-west-2 if none defined)\nregion=$(aws configure get region)\nregion=${region:-us-west-2}\n\nfullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n\n# If the repository doesn't exist in ECR, create it.\n\naws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n\nif [ $? -ne 0 ]\nthen\n    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\nfi\n\n# Get the login command from ECR and execute it directly\n$(aws ecr get-login --region ${region} --no-include-email)\n\n# Build the docker image locally with the image name and then push it to ECR\n# with the full name.\n\ndocker build  -t ${algorithm_name} .\ndocker tag ${algorithm_name} ${fullname}\n\ndocker push ${fullname}"},{"cell_type":"markdown","metadata":{},"source":["Once you have your container packaged, you can use it to train and serve models. Let's do that with the algorithm we made above.\n","\n","## Set up the environment\n","\n","Here we specify a bucket to use and the role that will be used for working with SageMaker."]},{"cell_type":"code","execution_count":72,"metadata":{},"outputs":[],"source":"# S3 prefix\nprefix = 'sagemaker-keras-text-classification'\n\n# Define IAM role\nimport boto3\nimport re\n\nimport os\nimport numpy as np\nimport pandas as pd\nfrom sagemaker import get_execution_role\n\nrole = get_execution_role()"},{"cell_type":"markdown","metadata":{},"source":["## Create the session\n","\n","The session remembers our connection parameters to SageMaker. We'll use it to perform all of our SageMaker operations."]},{"cell_type":"code","execution_count":73,"metadata":{},"outputs":[],"source":"import sagemaker as sage\nfrom time import gmtime, strftime\n\nsess = sage.Session()"},{"cell_type":"markdown","metadata":{},"source":["## Upload the data for training\n","\n","When training large models with huge amounts of data, you'll typically use big data tools, like Amazon Athena, AWS Glue, or Amazon EMR, to create your data in S3.  \n","\n","We can use use the tools provided by the SageMaker Python SDK to upload the data to a default bucket. "]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[],"source":"WORK_DIRECTORY = 'data'\n\ndata_location = sess.upload_data(WORK_DIRECTORY, key_prefix=prefix)"},{"cell_type":"markdown","metadata":{},"source":["## Create an estimator and fit the model\n","\n","In order to use SageMaker to fit our algorithm, we'll create an `Estimator` that defines how to use the container to to train. This includes the configuration we need to invoke SageMaker training:\n","\n","* The __container name__. This is constucted as in the shell commands above.\n","* The __role__. As defined above.\n","* The __instance count__ which is the number of machines to use for training.\n","* The __instance type__ which is the type of machine to use for training.\n","* The __output path__ determines where the model artifact will be written.\n","* The __session__ is the SageMaker session object that we defined above.\n","\n","Then we use fit() on the estimator to train against the data that we uploaded above."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["2019-10-09 17:51:04 Starting - Starting the training job...\n","2019-10-09 17:51:06 Starting - Launching requested ML instances...."]}],"source":"account = sess.boto_session.client('sts').get_caller_identity()['Account']\nregion = sess.boto_session.region_name\nimage = '{}.dkr.ecr.{}.amazonaws.com/sagemaker-keras-text-classification'.format(account, region)\n\ntree = sage.estimator.Estimator(image,\n                       role, 1, 'ml.c5.2xlarge',\n                       output_path=\"s3://{}/output\".format(sess.default_bucket()),\n                       sagemaker_session=sess)\n\ntree.fit(data_location)"},{"cell_type":"markdown","metadata":{},"source":["## Deploy the model\n","\n","Deploying the model to SageMaker hosting just requires a `deploy` call on the fitted model. This call takes an instance count, instance type, and optionally serializer and deserializer functions. These are used when the resulting predictor is created on the endpoint."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"from sagemaker.predictor import json_serializer\npredictor = tree.deploy(1, 'ml.m5.xlarge', serializer=json_serializer)"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"#request = { \"input\": \"‘Deadpool 2’ Has More Swearing, Slicing and Dicing from Ryan Reynolds\"}\n#print(predictor.predict(request).decode('utf-8'))"},{"cell_type":"markdown","metadata":{},"source":["## Clean Up\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"sess.delete_endpoint(predictor.endpoint)"}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}